{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfuAmh_uBLB3"
   },
   "source": [
    "**Define a Class and all the Relevant Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ygrz1kOj-H9j"
   },
   "outputs": [],
   "source": [
    "## Install Relevant Packages\n",
    "# !pip install rdkit\n",
    "# !pip install pubchempy\n",
    "# !pip install bioservices\n",
    "# !pip install biopython\n",
    "\n",
    "## Import Relevant Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bioservices import UniProt\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "import joblib\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class DrugDiscoveryPipeline:\n",
    "    def __init__(self, dataset_path, external_test_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.external_test_path = external_test_path\n",
    "        self.data = None\n",
    "        self.features = None\n",
    "        self.target = None\n",
    "        self.models = []\n",
    "        self.best_model_info = None\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    ## Import Data\n",
    "    def load_dataset(self):\n",
    "        self.data = pd.read_csv(self.dataset_path)\n",
    "        print(\"Dataset Summary:\")\n",
    "        print(self.data.info())\n",
    "\n",
    "    ## Sample the Dataset\n",
    "    def preprocess_data(self, sample_size=1000):\n",
    "        sampled_df = self.data.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "        sampled_df.dropna(inplace=True)\n",
    "        self.data = sampled_df\n",
    "\n",
    "    ## Compute Molecular Features of the Drug Molecules from SMILES Strings\n",
    "    ## https://www.rdkit.org/docs/source/rdkit.Chem.Descriptors.html\n",
    "    def compute_molecular_descriptors(self, pubchem_cid):\n",
    "        try:\n",
    "            smiles = self.get_smiles_from_pubchem(pubchem_cid)\n",
    "            if smiles:\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                if mol:\n",
    "                    return [\n",
    "                        Descriptors.MolWt(mol),\n",
    "                        Descriptors.MolLogP(mol),\n",
    "                        Descriptors.NumHDonors(mol),\n",
    "                        Descriptors.NumHAcceptors(mol),\n",
    "                        Descriptors.TPSA(mol),\n",
    "                        Descriptors.FractionCSP3(mol),\n",
    "                        Descriptors.NumRotatableBonds(mol),\n",
    "                        Descriptors.NumAromaticRings(mol),\n",
    "                        Descriptors.HeavyAtomCount(mol)\n",
    "                    ]\n",
    "        except Exception:\n",
    "            pass\n",
    "        return [np.nan] * 9\n",
    "\n",
    "    ## Compute Protein Features relavant to Drug-Protein Binding from corresponding Amino Acid Sequences\n",
    "    ## https://biopython.org/docs/1.75/api/Bio.SeqUtils.ProtParam.html\n",
    "    def encode_protein_features(self, uniprot_id):\n",
    "        try:\n",
    "            sequence = self.get_protein_sequence(uniprot_id)\n",
    "            print(f\"Protein sequence for {uniprot_id}: {sequence}\")\n",
    "\n",
    "            if sequence:\n",
    "                analysis = ProteinAnalysis(sequence)\n",
    "                features = {\n",
    "                    \"length\": len(sequence),\n",
    "                    \"aromaticity\": analysis.aromaticity(),\n",
    "                    \"instability_index\": analysis.instability_index(),\n",
    "                    \"isoelectric_point\": analysis.isoelectric_point(),\n",
    "                    \"gravy\": analysis.gravy(),\n",
    "                    \"molecular_weight\": analysis.molecular_weight(),\n",
    "                    \"flexibility_mean\": np.mean(analysis.flexibility()),\n",
    "                    \"extinction_coeff_reduced\": analysis.molar_extinction_coefficient()[0],\n",
    "                    \"extinction_coeff_disulfide\": analysis.molar_extinction_coefficient()[1],\n",
    "                }\n",
    "                secondary_structures = analysis.secondary_structure_fraction()\n",
    "                features.update({\n",
    "                    \"helix_fraction\": secondary_structures[0],\n",
    "                    \"sheet_fraction\": secondary_structures[1],\n",
    "                    \"coil_fraction\": secondary_structures[2],\n",
    "                })\n",
    "                aa_composition = analysis.get_amino_acids_percent()\n",
    "                features.update(aa_composition)\n",
    "                return list(features.values())\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing sequence for UniProt ID {uniprot_id}: {e}\")\n",
    "            return [np.nan] * len(features)  # Return NaNs in case of failure\n",
    "        return [np.nan] * len(features)\n",
    "\n",
    "    ## Retrieve SMILES Strings from the Pubchem IDs\n",
    "    ## https://pubchempy.readthedocs.io/en/latest/api.html\n",
    "    def get_smiles_from_pubchem(self, pubchem_cid):\n",
    "        import pubchempy as pcp\n",
    "        try:\n",
    "            compound = pcp.Compound.from_cid(pubchem_cid)\n",
    "            return compound.isomeric_smiles\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    ## Retrieve Amino Acid Sequence of the Proteins from the UniProt IDs\n",
    "    ## https://bioservices.readthedocs.io/en/latest/_modules/bioservices/uniprot.html\n",
    "    def get_protein_sequence(self, uniprot_id):\n",
    "        uniprot_service = UniProt()\n",
    "        try:\n",
    "            result = uniprot_service.retrieve(uniprot_id, frmt=\"fasta\")\n",
    "            sequence = ''.join(result.split('\\n')[1:])\n",
    "            return sequence\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    ## Create Dataframes from Drug Features and Protein Features and then Combine them\n",
    "    def extract_features(self):\n",
    "        compound_features = self.data['pubchem_cid'].astype(int).apply(self.compute_molecular_descriptors)\n",
    "        compound_features_df = pd.DataFrame(compound_features.tolist(), columns=[\n",
    "            'MolWt', 'MolLogP', 'NumHDonors', 'NumHAcceptors', 'TPSA',\n",
    "            'FractionCSP3', 'NumRotatableBonds', 'NumAromaticRings', 'HeavyAtomCount'\n",
    "        ])\n",
    "\n",
    "        print(compound_features_df)\n",
    "\n",
    "        protein_features = self.data['UniProt_ID'].apply(self.encode_protein_features)\n",
    "        protein_features_df = pd.DataFrame(protein_features.tolist(), columns=[\n",
    "            \"length\", \"aromaticity\", \"instability_index\", \"isoelectric_point\", \"gravy\",\n",
    "            \"molecular_weight\", \"flexibility_mean\", \"extinction_coeff_reduced\",\n",
    "            \"extinction_coeff_disulfide\", \"helix_fraction\", \"sheet_fraction\", \"coil_fraction\"\n",
    "        ] + [f\"aa_{aa}\" for aa in \"ACDEFGHIKLMNPQRSTVWY\"])\n",
    "\n",
    "        # Convert kiba_score_estimated column to numeric using map()\n",
    "        self.data['kiba_score_estimated'] = self.data['kiba_score_estimated'].map({True: 1, False: 0})\n",
    "\n",
    "        # Combine all features into a single DataFrame\n",
    "        self.features = pd.concat([\n",
    "            compound_features_df, protein_features_df,\n",
    "            self.data[['kiba_score_estimated']].reset_index(drop=True)\n",
    "        ], axis=1)\n",
    "\n",
    "        # Drop NaN rows and separate target\n",
    "        self.features.dropna(inplace=True)\n",
    "        self.target = self.data['kiba_score']\n",
    "\n",
    "    ## Train-Test Split\n",
    "    def train_test_split(self):\n",
    "        return train_test_split(self.features, self.target, test_size=0.2, random_state=42)\n",
    "\n",
    "    ## Model Evaluation\n",
    "    def train_and_evaluate(self, model, X_train, y_train, X_test, y_test):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        return {\"RMSE\": rmse, \"R2\": r2, \"model\": model}\n",
    "\n",
    "    ## Run Different Machine Learning Models and Save the Best Model\n",
    "    def run_ml_models(self, X_train, y_train, X_test, y_test):\n",
    "        self.models = [\n",
    "            {\"name\": \"Linear Regression\", \"model\": LinearRegression()},\n",
    "            {\"name\": \"LightGBM\", \"model\": LGBMRegressor(n_estimators=1000, learning_rate=0.05, random_state=42, verbose=-1)},\n",
    "            {\"name\": \"Random Forest\", \"model\": RandomForestRegressor(n_estimators=100, random_state=42)}\n",
    "        ]\n",
    "\n",
    "        self.best_model_info = {\"name\": None, \"rmse\": float('inf'), \"model\": None}\n",
    "\n",
    "        for model_info in self.models:\n",
    "            metrics = self.train_and_evaluate(model_info[\"model\"], X_train, y_train, X_test, y_test)\n",
    "            print(f\"{model_info['name']} - RMSE: {metrics['RMSE']:.4f}, R2: {metrics['R2']:.4f}\\n\")\n",
    "\n",
    "            if metrics[\"RMSE\"] < self.best_model_info[\"rmse\"]:\n",
    "                self.best_model_info = {\n",
    "                    \"name\": model_info[\"name\"],\n",
    "                    \"rmse\": metrics[\"RMSE\"],\n",
    "                    \"model\": metrics[\"model\"]\n",
    "                }\n",
    "\n",
    "        # Save the best ML model\n",
    "        joblib.dump(self.best_model_info[\"model\"], f\"best_ml_model_{self.best_model_info['name'].replace(' ', '_')}.pkl\")\n",
    "        print(f\"Best ML model ({self.best_model_info['name']}) saved as best_ml_model_{self.best_model_info['name'].replace(' ', '_')}.pkl\")\n",
    "\n",
    "    ## Build a Deep Neural Network for Model Training and Save it\n",
    "    def build_and_train_dnn(self, X_train_scaled, y_train, X_test_scaled, y_test):\n",
    "        dnn_model = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "\n",
    "        dnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "        dnn_model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "        # Save the trained model\n",
    "        dnn_model.save('dnn_model.h5')  # Saves the model to a file\n",
    "        # dnn_model.save('/content/dnn_model.h5')\n",
    "        print(\"DNN model saved successfully as dnn_model.h5\")\n",
    "\n",
    "        y_pred_dnn = dnn_model.predict(X_test_scaled).flatten()\n",
    "        rmse_dnn = np.sqrt(mean_squared_error(y_test, y_pred_dnn))\n",
    "        r2_dnn = r2_score(y_test, y_pred_dnn)\n",
    "\n",
    "        return dnn_model, {\"RMSE\": rmse_dnn, \"R2\": r2_dnn}\n",
    "\n",
    "    ## Load External Dataset for Testing the best ML model and the Deep Learning Model\n",
    "    def load_external_test_data(self):\n",
    "        external_test_data = pd.read_csv(self.external_test_path)\n",
    "        external_test_data.dropna(inplace=True)\n",
    "        return external_test_data\n",
    "\n",
    "    ## Predict Binding Affinity Between Drug-Protein Pairs in the External Test Dataset and Save the results\n",
    "    def predict_external(self, external_test_data):\n",
    "        external_test_data['pubchem_cid'] = external_test_data['pubchem_cid'].astype(int)\n",
    "        compound_features = external_test_data['pubchem_cid'].apply(self.compute_molecular_descriptors)\n",
    "        compound_features_df = pd.DataFrame(compound_features.tolist(), columns=[\n",
    "            'MolWt', 'MolLogP', 'NumHDonors', 'NumHAcceptors', 'TPSA',\n",
    "            'FractionCSP3', 'NumRotatableBonds', 'NumAromaticRings', 'HeavyAtomCount'\n",
    "        ])\n",
    "\n",
    "        protein_features = external_test_data['UniProt_ID'].apply(self.encode_protein_features)\n",
    "        protein_features_df = pd.DataFrame(protein_features.tolist(), columns=[\n",
    "            \"length\", \"aromaticity\", \"instability_index\", \"isoelectric_point\", \"gravy\",\n",
    "            \"molecular_weight\", \"flexibility_mean\", \"extinction_coeff_reduced\",\n",
    "            \"extinction_coeff_disulfide\", \"helix_fraction\", \"sheet_fraction\", \"coil_fraction\"\n",
    "        ] + [f\"aa_{aa}\" for aa in \"ACDEFGHIKLMNPQRSTVWY\"])\n",
    "\n",
    "        external_features = pd.concat([\n",
    "            compound_features_df, protein_features_df,\n",
    "            external_test_data[['kiba_score_estimated']].reset_index(drop=True)\n",
    "        ], axis=1)\n",
    "\n",
    "        external_features.dropna(inplace=True)\n",
    "        external_features_scaled = self.scaler.transform(external_features)\n",
    "\n",
    "        ml_predictions = self.best_model_info[\"model\"].predict(external_features)\n",
    "        dnn_model = load_model('dnn_model.h5')\n",
    "        dnn_predictions = dnn_model.predict(external_features_scaled).flatten()\n",
    "\n",
    "        external_test_data['kiba_score_pred_ml'] = ml_predictions\n",
    "        external_test_data['kiba_score_pred_dnn'] = dnn_predictions\n",
    "        external_test_data.to_csv('external_test_predictions.csv', index=False)\n",
    "\n",
    "        return external_test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyVELaX7BACn"
   },
   "source": [
    "**Define a Pipeline and Run the Pipeline Step by Step for Model Training**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uLVAfNZBYAX"
   },
   "outputs": [],
   "source": [
    "pipeline = DrugDiscoveryPipeline(dataset_path='Deloitte_DrugDiscovery_dataset.csv', external_test_path='external_test_dataset.csv')\n",
    "\n",
    "pipeline.load_dataset()\n",
    "\n",
    "pipeline.preprocess_data()\n",
    "\n",
    "pipeline.extract_features()\n",
    "\n",
    "pipeline.train_test_split()\n",
    "\n",
    "pipeline.run_ml_models(X_train, y_train, X_test, y_test)\n",
    "\n",
    "pipeline.build_and_train_dnn(X_train_scaled, y_train, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6CzIcgzBnzR"
   },
   "source": [
    "**Run the Pipeline for testing the Best ML model and the Deep Neural Network Model with External Dataset**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xt4CoW0B1I6"
   },
   "outputs": [],
   "source": [
    "pipeline.load_external_test_data()\n",
    "\n",
    "pipeline.predict_external(external_test_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
